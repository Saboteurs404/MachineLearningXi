{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Keras Tuner 简介\n",
    "\n",
    "本页内容\n",
    "- 概述\n",
    "- 设置\n",
    "- 下载并准备数据集\n",
    "- 定义模型\n",
    "- 实例化调节器并执行超调\n",
    "- 训练模型\n",
    "- 总结\n",
    "\n",
    "\n",
    "## 概述\n",
    "\n",
    "Keras tuner是一个库，可以帮助你为Tensorflow程序选择最佳的超参数集。为您的机器学习（ML）应用选择正确的超参数集，这一过程称为超参数调节或超调\n",
    "\n",
    "超参数是控制训练过程和机器学习模型的拓扑的变量，这些变量在训练过程汇总保持不变，并会直接影响机器学习程序的性能，超参数有两种类型：\n",
    "\n",
    "- 模型超参数：影响模型的选择，例如隐藏层的数量和宽度\n",
    "- 算法超参数：影响学习算法的速度和质量，例如随机梯度下降（SGD）的学习率以及K紧邻（KNN）分类器的近邻数\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# SECTION: 设置\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 下载并准备数据集\n",
    "\n",
    "在本教程中，您将使用 Keras Tuner 为某个对 Fashion MNIST 数据集内的服装图像进行分类的机器学习模型找到最佳超参数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# SECTION： 加载数据\n",
    "\n",
    "(img_train, label_train), (img_test, label_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# image的数字标准化可以提高后续训练模型的准确率，因为image的数字是从0到255的值，所以最简单的标准化方式是除以255\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型\n",
    "构建用于超调的模型时，除了模型架构之外，还要定义超参数搜索空间，您为超调设置的模型称为超模型\n",
    "\n",
    "您可以通过两种方式定义超模型\n",
    "\n",
    "- 使用模型构建攻击函数\n",
    "- 将Keras Tuner API的HyperModel类子类化\n",
    "\n",
    "在本教程中，您将使用模型构建工具函数来定义图像分类模型。模型构建工具函数将返回已编译的模型，并使用您以内嵌方式定义的超参数对模型进行超调。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 返回一个构建好的模型（compiled model，指整体模型结构已经搭好，包括损失函数的定义等等，但模型还未经过训练）：\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 实例化调节器并执行超调\n",
    "\n",
    "实例化调节器以执行超调，Keras Tuner 提供了四种调节器：RandomSearch、Hyperband、BayesianOptimaizaation和Sklearn,您将使用Hyperband调机器\n",
    "\n",
    "要实例化Hyperband调节器，必须指定超模型，要优化的objective和要训练的最大周期数（max_epochs）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "            objective='val_accuracy',\n",
    "            max_epochs=10,\n",
    "            factor=3,\n",
    "            directory='my_dir',\n",
    "            project_name='intro_to_kt'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperband调节算法使用自适应资源分配和早停法来快速收敛到高性能模型，该过程才用体育经济争冠模式的排除法。算法会将大量模型训练多个周期，并仅将性能最高的一半模型送入到下一轮训练，Hyperband通过计算1 + log（factor(max_epochs)）并将其向上舍入到最近的整数来确定要训练的模型的数量\n",
    "\n",
    "创建回调以在验证损失达到特定值后提前停止训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "运行超参数搜索，除了上面的回调外， 搜索方法的参数也与tf.keras.model.fit所用参数相同"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 Complete [00h 01m 24s]\n",
      "val_accuracy: 0.8922500014305115\n",
      "\n",
      "Best val_accuracy So Far: 0.8922500014305115\n",
      "Total elapsed time: 00h 09m 08s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 448 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2,\n",
    " callbacks=[stop_early])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练模型\n",
    "\n",
    "使用从搜索中获得的超参数找到训练模型的最佳周期数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4930 - accuracy: 0.8259 - val_loss: 0.3992 - val_accuracy: 0.8590\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3686 - accuracy: 0.8659 - val_loss: 0.3478 - val_accuracy: 0.8717\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3337 - accuracy: 0.8771 - val_loss: 0.4192 - val_accuracy: 0.8462\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3062 - accuracy: 0.8876 - val_loss: 0.3412 - val_accuracy: 0.8767\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2856 - accuracy: 0.8935 - val_loss: 0.3250 - val_accuracy: 0.8838\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2706 - accuracy: 0.8996 - val_loss: 0.3111 - val_accuracy: 0.8889\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2565 - accuracy: 0.9047 - val_loss: 0.3268 - val_accuracy: 0.8836\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2451 - accuracy: 0.9074 - val_loss: 0.3464 - val_accuracy: 0.8790\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2361 - accuracy: 0.9122 - val_loss: 0.3405 - val_accuracy: 0.8823\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2283 - accuracy: 0.9138 - val_loss: 0.3083 - val_accuracy: 0.8923\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2169 - accuracy: 0.9180 - val_loss: 0.3239 - val_accuracy: 0.8897\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2091 - accuracy: 0.9216 - val_loss: 0.3283 - val_accuracy: 0.8878\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2004 - accuracy: 0.9240 - val_loss: 0.3263 - val_accuracy: 0.8922\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1941 - accuracy: 0.9272 - val_loss: 0.3345 - val_accuracy: 0.8920\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1900 - accuracy: 0.9288 - val_loss: 0.3273 - val_accuracy: 0.8885\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1794 - accuracy: 0.9318 - val_loss: 0.3278 - val_accuracy: 0.8867\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1756 - accuracy: 0.9350 - val_loss: 0.3417 - val_accuracy: 0.8889\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1681 - accuracy: 0.9364 - val_loss: 0.3357 - val_accuracy: 0.8933\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1631 - accuracy: 0.9383 - val_loss: 0.3387 - val_accuracy: 0.8922\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1594 - accuracy: 0.9401 - val_loss: 0.3418 - val_accuracy: 0.8957\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1523 - accuracy: 0.9430 - val_loss: 0.3545 - val_accuracy: 0.8911\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1480 - accuracy: 0.9449 - val_loss: 0.3702 - val_accuracy: 0.8910\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1453 - accuracy: 0.9445 - val_loss: 0.3750 - val_accuracy: 0.8898\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1386 - accuracy: 0.9475 - val_loss: 0.3476 - val_accuracy: 0.8960\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1359 - accuracy: 0.9489 - val_loss: 0.3708 - val_accuracy: 0.8922\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1338 - accuracy: 0.9496 - val_loss: 0.3691 - val_accuracy: 0.8950\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1295 - accuracy: 0.9516 - val_loss: 0.4516 - val_accuracy: 0.8784\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1261 - accuracy: 0.9527 - val_loss: 0.3731 - val_accuracy: 0.8942\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1198 - accuracy: 0.9561 - val_loss: 0.4132 - val_accuracy: 0.8904\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1192 - accuracy: 0.9549 - val_loss: 0.3949 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1159 - accuracy: 0.9560 - val_loss: 0.4056 - val_accuracy: 0.8895\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1135 - accuracy: 0.9577 - val_loss: 0.4081 - val_accuracy: 0.8923\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1104 - accuracy: 0.9585 - val_loss: 0.4490 - val_accuracy: 0.8872\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1082 - accuracy: 0.9591 - val_loss: 0.4008 - val_accuracy: 0.8981\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1030 - accuracy: 0.9614 - val_loss: 0.4169 - val_accuracy: 0.8929\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1031 - accuracy: 0.9619 - val_loss: 0.4461 - val_accuracy: 0.8923\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1010 - accuracy: 0.9614 - val_loss: 0.4318 - val_accuracy: 0.8939\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0960 - accuracy: 0.9638 - val_loss: 0.4544 - val_accuracy: 0.8926\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0968 - accuracy: 0.9626 - val_loss: 0.4484 - val_accuracy: 0.8922\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0930 - accuracy: 0.9657 - val_loss: 0.4304 - val_accuracy: 0.8951\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0912 - accuracy: 0.9660 - val_loss: 0.4485 - val_accuracy: 0.8906\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 0.5075 - val_accuracy: 0.8898\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0918 - accuracy: 0.9655 - val_loss: 0.5387 - val_accuracy: 0.8864\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0844 - accuracy: 0.9688 - val_loss: 0.5116 - val_accuracy: 0.8898\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 0.4796 - val_accuracy: 0.8898\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0815 - accuracy: 0.9702 - val_loss: 0.4770 - val_accuracy: 0.8923\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0828 - accuracy: 0.9692 - val_loss: 0.5107 - val_accuracy: 0.8882\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0798 - accuracy: 0.9704 - val_loss: 0.5097 - val_accuracy: 0.8910\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0772 - accuracy: 0.9712 - val_loss: 0.5091 - val_accuracy: 0.8913\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0735 - accuracy: 0.9726 - val_loss: 0.5262 - val_accuracy: 0.8921\n",
      "Best epoch: 34\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = model.fit(img_train, label_train, epochs = 50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "\n",
    "print('Best epoch: %d' % (best_epoch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实例化超模型并使用上面的最佳周期数对其进行训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.4920 - accuracy: 0.8248 - val_loss: 0.4086 - val_accuracy: 0.8512\n",
      "Epoch 2/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3676 - accuracy: 0.8656 - val_loss: 0.3737 - val_accuracy: 0.8678\n",
      "Epoch 3/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3322 - accuracy: 0.8786 - val_loss: 0.3458 - val_accuracy: 0.8728\n",
      "Epoch 4/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3075 - accuracy: 0.8857 - val_loss: 0.3412 - val_accuracy: 0.8747\n",
      "Epoch 5/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2845 - accuracy: 0.8945 - val_loss: 0.3298 - val_accuracy: 0.8808\n",
      "Epoch 6/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2733 - accuracy: 0.8994 - val_loss: 0.3285 - val_accuracy: 0.8832\n",
      "Epoch 7/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2571 - accuracy: 0.9036 - val_loss: 0.3184 - val_accuracy: 0.8886\n",
      "Epoch 8/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2464 - accuracy: 0.9078 - val_loss: 0.3178 - val_accuracy: 0.8877\n",
      "Epoch 9/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2361 - accuracy: 0.9120 - val_loss: 0.3138 - val_accuracy: 0.8908\n",
      "Epoch 10/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2237 - accuracy: 0.9157 - val_loss: 0.3310 - val_accuracy: 0.8846\n",
      "Epoch 11/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2159 - accuracy: 0.9192 - val_loss: 0.3129 - val_accuracy: 0.8906\n",
      "Epoch 12/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2077 - accuracy: 0.9220 - val_loss: 0.3093 - val_accuracy: 0.8951\n",
      "Epoch 13/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1996 - accuracy: 0.9248 - val_loss: 0.3067 - val_accuracy: 0.8937\n",
      "Epoch 14/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1928 - accuracy: 0.9269 - val_loss: 0.3384 - val_accuracy: 0.8888\n",
      "Epoch 15/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1882 - accuracy: 0.9284 - val_loss: 0.3200 - val_accuracy: 0.8968\n",
      "Epoch 16/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1798 - accuracy: 0.9316 - val_loss: 0.3556 - val_accuracy: 0.8824\n",
      "Epoch 17/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1729 - accuracy: 0.9351 - val_loss: 0.3611 - val_accuracy: 0.8845\n",
      "Epoch 18/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1695 - accuracy: 0.9366 - val_loss: 0.3268 - val_accuracy: 0.8969\n",
      "Epoch 19/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1627 - accuracy: 0.9386 - val_loss: 0.3317 - val_accuracy: 0.8932\n",
      "Epoch 20/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1573 - accuracy: 0.9405 - val_loss: 0.3412 - val_accuracy: 0.8942\n",
      "Epoch 21/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1536 - accuracy: 0.9419 - val_loss: 0.3607 - val_accuracy: 0.8909\n",
      "Epoch 22/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1467 - accuracy: 0.9444 - val_loss: 0.3541 - val_accuracy: 0.8965\n",
      "Epoch 23/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1441 - accuracy: 0.9458 - val_loss: 0.3830 - val_accuracy: 0.8908\n",
      "Epoch 24/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1378 - accuracy: 0.9478 - val_loss: 0.3811 - val_accuracy: 0.8893\n",
      "Epoch 25/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1368 - accuracy: 0.9480 - val_loss: 0.3814 - val_accuracy: 0.8911\n",
      "Epoch 26/34\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1325 - accuracy: 0.9497 - val_loss: 0.3689 - val_accuracy: 0.8979\n",
      "Epoch 27/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1261 - accuracy: 0.9538 - val_loss: 0.3930 - val_accuracy: 0.8927\n",
      "Epoch 28/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1238 - accuracy: 0.9538 - val_loss: 0.4140 - val_accuracy: 0.8914\n",
      "Epoch 29/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1220 - accuracy: 0.9540 - val_loss: 0.3881 - val_accuracy: 0.8949\n",
      "Epoch 30/34\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1194 - accuracy: 0.9549 - val_loss: 0.4156 - val_accuracy: 0.8942\n",
      "Epoch 31/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1145 - accuracy: 0.9570 - val_loss: 0.4121 - val_accuracy: 0.8932\n",
      "Epoch 32/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1116 - accuracy: 0.9580 - val_loss: 0.4099 - val_accuracy: 0.8963\n",
      "Epoch 33/34\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1082 - accuracy: 0.9594 - val_loss: 0.4269 - val_accuracy: 0.8891\n",
      "Epoch 34/34\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1081 - accuracy: 0.9600 - val_loss: 0.4326 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x20e240f6230>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "hypermodel.fit(img_train, label_train, epochs = best_epoch, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "要完成本教程请在测试数据上评估超模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.8804\n",
      "[test loss, test accuracy: [0.47123461961746216, 0.8804000020027161]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "\n",
    "print(\"[test loss, test accuracy:\", eval_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "my_dir/intro_to_kt 目录中包含了在超参数搜索期间每次试验（模型配置）运行的详细日志和检查点。如果重新运行超参数搜索，Keras Tuner 将使用这些日志中记录的现有状态来继续搜索。要停用此行为，请在实例化调节器时传递一个附加的 overwrite = True 参数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
