{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 加载和预处理图像\n",
    "\n",
    "- 设置\n",
    "    - 下载花卉数据集\n",
    "- 使用Keras使用程序加载数据\n",
    "    - 创建数据集\n",
    "    - 可视化数据\n",
    "    - 标准化数据\n",
    "    - 配置数据集以提高性能\n",
    "    - 训练模型\n",
    "- 使用tf.data进行更精细的控制\n",
    "    - 配置数据集以提高性能\n",
    "    - 可视化数据\n",
    "    - 继续训练模型\n",
    "- 使用tensorflow数据集\n",
    "- 下一步\n",
    "\n",
    "\n",
    "本教程展示了三种方式加载和预处理数据集：\n",
    "- 使用高级Keras预处理使用程序（例如tf.keras.utils.image_dataset_from_directory）和层（例如tf.keras.layers.Rescaling）来读取磁盘上的图像目录\n",
    "- 将使用tf.data从头开始编写自己的输入管道\n",
    "- 从tensorflow数据集中提供的大型目录中下载数据集\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SECTION：设置\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 下载花卉数据集\n",
    "本教程使用包含数千张花朵照片的数据集，花朵数据集保护五个子目录，每个类一个：\n",
    "flowers_photos/\n",
    "    daisy/\n",
    "    dandelion/\n",
    "    roses/\n",
    "    sunflowers/\n",
    "    tulips/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEOFError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m\n\u001B[0;32m      2\u001B[0m dataset_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m archive \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextract\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m pathlib\u001B[38;5;241m.\u001B[39mPath(archive)\u001B[38;5;241m.\u001B[39mwith_suffix(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:375\u001B[0m, in \u001B[0;36mget_file\u001B[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001B[0m\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m untar_fpath\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extract:\n\u001B[1;32m--> 375\u001B[0m     \u001B[43m_extract_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatadir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marchive_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fpath\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\site-packages\\keras\\src\\utils\\data_utils.py:179\u001B[0m, in \u001B[0;36m_extract_archive\u001B[1;34m(file_path, path, archive_format)\u001B[0m\n\u001B[0;32m    176\u001B[0m         archive\u001B[38;5;241m.\u001B[39mextractall(path)\n\u001B[0;32m    177\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;66;03m# Tar archive, perhaps unsafe. Filter paths.\u001B[39;00m\n\u001B[1;32m--> 179\u001B[0m         \u001B[43marchive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextractall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmembers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_filter_safe_paths\u001B[49m\u001B[43m(\u001B[49m\u001B[43marchive\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (tarfile\u001B[38;5;241m.\u001B[39mTarError, \u001B[38;5;167;01mRuntimeError\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(path):\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\tarfile.py:2264\u001B[0m, in \u001B[0;36mTarFile.extractall\u001B[1;34m(self, path, members, numeric_owner, filter)\u001B[0m\n\u001B[0;32m   2259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tarinfo\u001B[38;5;241m.\u001B[39misdir():\n\u001B[0;32m   2260\u001B[0m         \u001B[38;5;66;03m# For directories, delay setting attributes until later,\u001B[39;00m\n\u001B[0;32m   2261\u001B[0m         \u001B[38;5;66;03m# since permissions can interfere with extraction and\u001B[39;00m\n\u001B[0;32m   2262\u001B[0m         \u001B[38;5;66;03m# extracting contents can reset mtime.\u001B[39;00m\n\u001B[0;32m   2263\u001B[0m         directories\u001B[38;5;241m.\u001B[39mappend(tarinfo)\n\u001B[1;32m-> 2264\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_attrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2265\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mnumeric_owner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_owner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2267\u001B[0m \u001B[38;5;66;03m# Reverse sort directories.\u001B[39;00m\n\u001B[0;32m   2268\u001B[0m directories\u001B[38;5;241m.\u001B[39msort(key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m a: a\u001B[38;5;241m.\u001B[39mname, reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\tarfile.py:2327\u001B[0m, in \u001B[0;36mTarFile._extract_one\u001B[1;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001B[0m\n\u001B[0;32m   2324\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2326\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2327\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_extract_member\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2328\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mset_attrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_attrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2329\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mnumeric_owner\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_owner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2330\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   2331\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle_fatal_error(e)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\tarfile.py:2410\u001B[0m, in \u001B[0;36mTarFile._extract_member\u001B[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001B[0m\n\u001B[0;32m   2407\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dbg(\u001B[38;5;241m1\u001B[39m, tarinfo\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   2409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tarinfo\u001B[38;5;241m.\u001B[39misreg():\n\u001B[1;32m-> 2410\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakefile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargetpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2411\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m tarinfo\u001B[38;5;241m.\u001B[39misdir():\n\u001B[0;32m   2412\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedir(tarinfo, targetpath)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\tarfile.py:2463\u001B[0m, in \u001B[0;36mTarFile.makefile\u001B[1;34m(self, tarinfo, targetpath)\u001B[0m\n\u001B[0;32m   2461\u001B[0m     target\u001B[38;5;241m.\u001B[39mtruncate()\n\u001B[0;32m   2462\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2463\u001B[0m     \u001B[43mcopyfileobj\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarinfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mReadError\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\tarfile.py:252\u001B[0m, in \u001B[0;36mcopyfileobj\u001B[1;34m(src, dst, length, exception, bufsize)\u001B[0m\n\u001B[0;32m    250\u001B[0m blocks, remainder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdivmod\u001B[39m(length, bufsize)\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(blocks):\n\u001B[1;32m--> 252\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(buf) \u001B[38;5;241m<\u001B[39m bufsize:\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exception(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munexpected end of data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\gzip.py:301\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 301\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\_compression.py:68\u001B[0m, in \u001B[0;36mDecompressReader.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreadinto\u001B[39m(\u001B[38;5;28mself\u001B[39m, b):\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b) \u001B[38;5;28;01mas\u001B[39;00m view, view\u001B[38;5;241m.\u001B[39mcast(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m byte_view:\n\u001B[1;32m---> 68\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbyte_view\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m         byte_view[:\u001B[38;5;28mlen\u001B[39m(data)] \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data)\n",
      "File \u001B[1;32mE:\\LocalRepository\\Anaconda3_envs\\deeplearning\\lib\\gzip.py:507\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m    505\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buf \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 507\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompressed file ended before the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    508\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend-of-stream marker was reached\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    510\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_read_data( uncompress )\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(uncompress)\n",
      "\u001B[1;31mEOFError\u001B[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(archive).with_suffix('')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 下载后的花卉照片，共有3670张图像\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m image_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mlist\u001B[39m(\u001B[43mdata_dir\u001B[49m\u001B[38;5;241m.\u001B[39mglob((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*/*.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m))))\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(image_count)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# 下载后的花卉照片，共有3670张图像\n",
    "image_count = len(list(data_dir.glob(('*/*.jpg'))))\n",
    "print(image_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 每个目录都包含该类型的花的图像，啫喱有一些玫瑰花\n",
    "roses = list(data_dir.glob('roses/*'))\n",
    "PIL.Image.open(str(roses[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Keras使用程序加载数据\n",
    "让我们使用有用的tf.keras.utils.image_dataset_from_directory使用程序从磁盘加载这些图像。\n",
    "\n",
    "### 创建数据集\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建数据集、\n",
    "# 为加载器定义一些参数\n",
    "batch_size = 32\n",
    "img_height= 180"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
